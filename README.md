# Automatic Triggering of Acoustic Traffic Sensing by Human Recognition Using Smartphone Accelerometer
This project is an Android Application (essentially a background service) which performs activity recognition using data from accelerometer sensor embedded in smartphones. The classes into which user activities are classified are Walking, Driving, Still or Neither. Neither includes all such activities which aren't included in the remaining activities such as simply using your phone, picking up device from a stationary position, standing, etc. Trained SVM classifier has been ported to Android which performs classification (activity recognition) on the go. If the device is found to be in a moving vehicle (Driving class), the service collects instantaneous location data and a 10 second sound sample. The service then sends the data over to the server for traffic sensing. 

## Getting Started
Follow the instructions get a copy of the project up and running on your local machine for development and testing purposes.

## Prerequisites
The development environment was set up on Microsoft Windows 10 Pro. The instructions have been written for the same. However, the same environment can be set up on different platforms as well.
1. [Android Studio](https://developer.android.com/studio/)
2. [Weka](https://www.cs.waikato.ac.nz/~ml/weka/downloading.html) this is optional and needed only if you wish to train your own SVM classifier. Also, better if you go for the package which includes Java JRE. (Should be around 265mB)
3. [WampServer](http://www.wampserver.com/en/) for setting up local server and testing the data sent by Android device

## Installing 
Installing the above softwares is a rather trivial task and needs no explaination.

## Deploying the app
1. To get the app for testing or further development, send a pull request or simply [download](https://github.com/prash1410/SensorTasks/archive/master.zip) the entire project, unzip and open with Android Studio.
2. In Android Studio, use inbuilt SDK Manager to ensure that you have SDK Platforms starting from Android 4.4 (Kitkat) to Android 8.1 (Oreo).
3. For first Gradle Build, ensure you have a proper Internet connection for Gradle to successfully download all the dependencies.
4. Connect your Android device via USB and run the app (I would discourage using Android Emulator).

## Using the app
On first run, the app would request the following three permissions. Make sure you grant all three of them.
- Access files and media
- Access location
- Record audio

The app interface would show three buttons labelled as: 
- ACCELEROMETER
- START ACCELEROMETER SERVICE
- DATA COLLECTION

**ACCELEROMETER** Button opens an activity to activate accelerometer for 15 seconds and count number of samples collected. (Useful in observing approximate sampling rate on different devices)

**DATA COLLECTION** button opens an activity for Data Collection. (More about this in later sections)

On **long pressing** the **START ACCELEROMETER SERVICE** button, you'll see a dialog prompting to choose a SVM model. Different models give different activity recognition accuracy. The name of the models signify the dataset, training kernel and parameters used and validation accuracy. Models named 'Ham' have been trained on partial dataset while others on full dataset. You can pick any model from the list and hit OK. After this, if you simply press the START ACCELEROMETER SERVICE button, your selected model will be used for activity recognition. Long pressing the button and choosing a model is optional since if you simply tap the button without picking a model, a default model will be used.
Tapping the button, fires a persistent notification and starts activity recognition service. The notification shows the activity recognized by the service at that instant. Do note that the service uses data from accelerometer for about 15 seconds the first time and 7.5 seconds subsequent times to perform activity recognition. The notification also shows a stop button which simply stops the service and dismisses the notification. Tapping on the notification itself does the same.

### Ouput generated by the service
The output generated by the service comprises of the collected sound samples, activity recognition logs, crash logs (in case of any crashes), and data fetched from server (if a local server has been set up).
The output files reside in **AcousticData** folder in the root of phone's internal storage. CSVData folder in AcousticData folder contains activity logs. The log file contains activity with timestamp followed by latitude and longitude.

## Data collection
**DATA COLLECTION** button opens an activity for Data Collection. The Radio Buttons allow to select the label for data which will be collected. Hit START DATA COLLECTION SERVICE button, to start collecting data. The button starts service which collects data from accelerometer in the background and labels the data with the selected Radio Button. Also, it fires a persistent notification which can be used to stop the collection service. 
The data collected by the service is stored in **DataCollection** folder in the root of internal storage. **Data.csv** file contains the usable data which includes all the extacted features plus the label of the data. The other files in the folder simply contain raw accelerometer data.

## Datasets
The datasets used for training SVM models can be found in [Datasets directory](https://github.com/prash1410/SensorTasks/tree/master/Datasets). Here's the Google Drive [link](https://drive.google.com/drive/folders/1ZLvCApZ7vbihuvPq6OBYfYDerY_-W0D8?usp=sharing) for the same. 
Dataset named 'Dataset (Ham)' is the partial dataset and has been collected on device Lenovo ZUK Z1. Dataset named 'Dataset (Combined)' has been collected on the following devices and is the full dataset
- Lenovo ZUK Z1, Android 7.1.2
- Motorola G5 Plus, Android 7.0
- Xiaomi Redmi 3s Prime, Android 6.0.1
- Xiaomi Mi Note 3, Android 6.0
  
Models in the Android app which have their starting with 'Ham' have been trained on partial dataset while the rest have been trained on full dataset. Dataset named 'Dataset (Other devices)' includes data from all of the above listed devices except for ZUK Z1.

## Training your own model
As briefly mentioned earlier, Weka has been used to train SVM models. To train your own model, you'll need to have your dataset and attributes and their order should be identical to the datasets which have been already used (if you don't want to change the Android code). Assuming you have the dataset, follow the steps
1. Start Weka, click **Explorer**
2. Click **Open file** and browse for your dataset. If your dataset is in .csv format (which most probably it'll be), made sure you select **CSV data files** from **Files of Type** dropdown list. Choose your dataset and click **Open**.
3. If you get an error check for the following things and if not proceed to step 4
    - Check the first row of the Dataset file. Make sure that all the attribute names are in the first row. Weka assumes that the first row contains attribute names and no two attribute names should be same. So if you have data values in the very first row instead of unique attribute names, you'll most likely get an error.
    - Make sure the labels of the data are contained in the very last column of the dataset file. This is where Weka assumes the labels to be.
    - Make sure all rows are of same length.
  
4. Click on **Classify** tab, click on **Choose**
5. From the list which appears, expand **functions** and click on **SMO** (which is SVM)
6. To immediate right of **Choose** button, there would be a field which contains text as **SMO -C 1.0......**. Click on that field
7. The dialog which appears will allow you to choose various kernels and kernel parameters for model training. Click **OK** upon choosing the desired parameters.
8. If you have a test set, check **Supplied test set** radio button and browse for your test set. Otherwise let **Cross-validation** be checked for 10 folds.
9. Click on **Start** to start training the classifier.
10. When training completes, right click on the **Result list** entry and choose **Save model**
11. Save your model wherever you like

## Using your model on Android
In Android Studio, in left pane (Project Explorer), under **App** folder, you should see **Assets** folder. Right click on it and select **Show in explorer**. Copy and paste your model in the directory. Now when you launch the app next time and long press START ACCELEROMETER SERVICE button, your model should appear in the list. Do note that the number of models displayed in the list is restricted to 13 entries. This can be changed [here](https://github.com/prash1410/SensorTasks/blob/a064ae4d358a2ba295f5065bc23ffc894e82b9fe/app/src/main/java/ps/uiet/chd/sensortasks/MainActivity.java#L141).

## Setting up local server
The server for handling data sent by Android service was set up using WampServer. Installing and setting up the same is pretty straightforward. However, do mind the following points to make the system work
- Unless you have **Put online** Wamp after configuring **router port forwarding**, make sure the Android device and the computer on which Wamp is configured are on same local network. (Tethering computer using Android device is the best option)
- Start Wamp, and when the icon in taskbar turns green, left click on the icon, choose **Apache** and then **hhtpd-vhosts.conf**
- Change 10th line to **Require all granted**
- Save the file and restart Wamp server
- To test if the device is able to communicate with the  WampServer, create a dummy PHP file in **C:\wamp64\www** directory. Do note that **www** directory is the default Wamp directory for PHP scripts and web pages. Note the IP Address of the computer and the name of your PHP file. And create a URL **http://{IP Address}/{your PHP file name}.php**

For example, **http//192.168.51.10/test.php**
- Access this URL from your phone's browser. If the results of PHP script are displayed wihtout any error, success! Otherwise something is not right!

## A few more needed tasks...
Head over [here](https://github.com/prash1410/SensorTasks/tree/master/Server%20Scripts) to find the required PHP and Python scripts which handle and process data sent by Android service. Copy the folders and the contents **(as it is!)** to **C:\wamp64\www** folder.

Also, on PhpMyAdmin, you might wanna create a database named **acousticdatabase**. Keep PhpMyAdmin credentials to default (i.e., username = root and no password). You can always change the mentioned things but make sure you edit the PHP scripts and Python script in the residing in PHPScripts and PythonScripts folder respectively to reflect the changes.

Also, in Android code, you would need to change the URL to the PHP scripts because the IP address of the WampServer would vary from network to network. You would need to change the IP address to your WampServer's IP [here](https://github.com/prash1410/SensorTasks/blob/e0a65c61f6c1723ce151d22e187a82fa67d8e36e/app/src/main/java/ps/uiet/chd/sensortasks/GetServerUpdates.java#L41) and [here](https://github.com/prash1410/SensorTasks/blob/e0a65c61f6c1723ce151d22e187a82fa67d8e36e/app/src/main/java/ps/uiet/chd/sensortasks/uploadSampleTask.java#L23).

## Finally...
If the everything goes well, when Android service detects 'Driving' for three consecutive times or more, the service should record 10 second sound sample and fetch instantaneous location data from GPS and send it to server. Make sure GPS is **enabled** and set to **High Accuracy** when you test the service. If you don't, the fetched latitude and longitude will be shown as empty. To verify if sound data is being successfully sent to the server, check your **C:\wamp64\www\PHPScripts\acoustic_data** folder. If sound files with .wav extension appear there, things are going swimmingly! Also, if you log on to PhpMyAdmin, you'll see **acousticdatabase** database getting populated with tables and new records. 

The names of the table in the database would be of the form **device_(four digit device ID)**. Device ID in Android code is created [here](https://github.com/prash1410/SensorTasks/blob/e0a65c61f6c1723ce151d22e187a82fa67d8e36e/app/src/main/java/ps/uiet/chd/sensortasks/AccelerometerBackgroundService.java#L129). The contents of each table include name of the sound sample, timestamp, latitude, longitude and a read flag. Read flag helps the Android service to differentiate between read and new records.

## Author
Prashant Sahu

Connect with me on [Facebook](https://www.facebook.com/PrashantSahu141), [Github](https://github.com/prash1410) or drop me an email at sahu.prashant@hotmail.com.
